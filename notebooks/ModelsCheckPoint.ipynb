{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # MODEL BUILDING\n",
    "\n",
    "# %% [markdown]\n",
    "# ## import the relevant libraries\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, mean_squared_error\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>kilometerage</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford Fiesta</td>\n",
       "      <td>FORD</td>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>175418</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vauxhall Corsa</td>\n",
       "      <td>VAUXHALL</td>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>175418</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vauxhall Zafira</td>\n",
       "      <td>VAUXHALL</td>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>175418</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peugeot 107</td>\n",
       "      <td>PEUGEOT</td>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>175418</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vauxhall Corsa</td>\n",
       "      <td>VAUXHALL</td>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>175418</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name manufacturer  year  age  kilometerage  engine transmission  \\\n",
       "0      Ford Fiesta         FORD  2003   22        175418  Petrol    Automatic   \n",
       "1   Vauxhall Corsa     VAUXHALL  2003   22        175418  Petrol    Automatic   \n",
       "2  Vauxhall Zafira     VAUXHALL  2003   22        175418  Petrol    Automatic   \n",
       "3      Peugeot 107      PEUGEOT  2003   22        175418  Petrol    Automatic   \n",
       "4   Vauxhall Corsa     VAUXHALL  2003   22        175418  Petrol    Automatic   \n",
       "\n",
       "   price  \n",
       "0   1500  \n",
       "1   1500  \n",
       "2   1500  \n",
       "3   1500  \n",
       "4   1500  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "data = pd.read_csv('../dataSet/cleaned_car_data2.csv')\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>age</th>\n",
       "      <th>kilometerage</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63968</th>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50404</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>84995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63969</th>\n",
       "      <td>466</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>4184</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>84995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63970</th>\n",
       "      <td>572</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>3057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63971</th>\n",
       "      <td>398</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>12824</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63972</th>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7903</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  manufacturer  age  kilometerage  engine  transmission  price\n",
       "63968    63             4    5         50404       3             0  84995\n",
       "63969   466            41    2          4184       2             0  84995\n",
       "63970   572            43    2          3057       0             0  84995\n",
       "63971   398            34    3         12824       3             0  85000\n",
       "63972    79             5    1          7903       2             0  85000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## drop the name and year columns because it is irrelevant in our model building\n",
    "\n",
    "# %%\n",
    "data = data.drop(['year'], axis=1)\n",
    "\n",
    "# %%\n",
    "data.head()\n",
    "\n",
    "# %%\n",
    "data['name'].unique()\n",
    "\n",
    "# %% [markdown]\n",
    "# # label encode the categorical values\n",
    "\n",
    "# %%\n",
    "le_name = LabelEncoder()\n",
    "le_manufacturer = LabelEncoder()\n",
    "le_engine = LabelEncoder()\n",
    "le_transmission = LabelEncoder()\n",
    "data['name'] = le_name.fit_transform(data['name'])\n",
    "data['manufacturer'] = le_manufacturer.fit_transform(data['manufacturer'])\n",
    "data['engine'] = le_engine.fit_transform(data['engine'])\n",
    "data['transmission'] = le_transmission.fit_transform(data['transmission'])\n",
    "\n",
    "# %%\n",
    "data.tail(\n",
    ")\n",
    "\n",
    "# %%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149 506 523 374  98 178 153 266 378 217  70 363 411 135  19 179 104 501\n",
      " 579 157 458 382 142 514 224 108 161 494 555 365 469 184 426 128 105 347\n",
      " 141 145 164 433 273 380 174 371 228 442 291 459 419  65 170 272 285 330\n",
      " 529 226 240  10 114 537  76 416 368 391 427 189 468 107 231 491 279 467\n",
      " 392 553   9   3 581 379 592 188 513  13 521 341 276  59 452 229 274 447\n",
      " 372 448 251 421 385 116 438 129 476 499  95 196 485 110 323 301 275 136\n",
      " 299 559 126 503 342 177 351 197 449 570 429 361 190 584 199  21 286 302\n",
      " 242 300 577 267  15 102 113 456 393 483 264 413 292 163 358 144 373 278\n",
      " 386 348 210 227  20 571 139 500 534 515 357 356 451 362 213 241 152  93\n",
      " 353 159 530 281 289 345 256  78 453 103 284 326 115 344 200  16 502   2\n",
      " 375 290 158 282 394 211 441 590 558 376 431 460 566 520 531 335 444 493\n",
      " 524 137 130 585 578 223 498 270 583 446 245 420 370 109 321 387 191 162\n",
      " 132 214 410 322 203 143 324 295 173   7 280 352 146  17 455 327 192 138\n",
      " 225 366  39 383 415 175 422 450 517 388 461 484 283 572 412 377 118  53\n",
      " 479 543  35  29 140 349 209 248  24 176  51 215 106 519  66 510 343 367\n",
      " 230  22 237 364 482 238 355 243 402 268 540 169   0 486  14 504 425 424\n",
      "  79  75  67 147  73 205 171  69 423 401 198 512 193 202 466 443 182 311\n",
      "  82 334 573  71 239 339 481 167 350 310 117 488 221 509 435 160 297 172\n",
      " 525 296  27 232 354 100 560 111 536 487 155 508 340 561  52 470 277 151\n",
      " 507 505 434 154 586 346  94 150 233  72 533 557 187 312 338 414 473 212\n",
      " 511 294 337 381 471 535 131 389 333 428   8 436 556 332 457 390 475 269\n",
      " 325 478 462 544  60 314 218 582 518 216  11 474 395 490 222 254  90  64\n",
      " 204  68 430 526 516 298 127 439 408 554 477 287  61 406  56  45 336   1\n",
      " 538 564 265  89  12 316 587  97 497 445   4 495 263 185 208 246 235 562\n",
      " 539 404 317 432 403 168 112 293 463 331 396 400  62 567 259  25 122 545\n",
      "  28  18 546 565  92 489 397 542 563 305 124 121 440 589 496 194  91  55\n",
      " 249 417 166 315 541 207  74 384 522  77 307 527 369 303  32 165 548  30\n",
      " 547 492 123 454 156 313 528 262 255 125 183 260  43 329  33 409 574 304\n",
      " 569 181  88 568 119  47  31 219 258 359  37 319  85 186 120 575 306 195\n",
      " 472 271 465 480 250 328 588 549 464 234 580 244  23  48 180 206 398 399\n",
      "  34  36   5 532  46  83  99   6  80 320 253  54  81 591  49 252  41 261\n",
      " 437  40  57 576 257 318  87 418 551  50 550 247 552 407  26 148  86 308\n",
      " 360 236 405  96 201 101  58  84 309  42  63 133 220 288 134  44  38]\n",
      "21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((51178, 6), (12795, 6), (51178,), (12795,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['name'].unique()) \n",
    "print(data[data['name'] == 1].shape[0])\n",
    "\n",
    "# %%\n",
    "# creating X and y variables\n",
    "X = data.drop(['price'], axis=1)\n",
    "y = data['price'] * 10\n",
    "X.head()\n",
    "y.head()\n",
    "\n",
    "# %%\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# %%\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55405405 0.61363636 0.0877193  0.19286727 0.         0.        ]\n",
      " [0.85472973 0.95454545 0.07017544 0.06141017 0.75       0.5       ]\n",
      " [0.51013514 0.61363636 0.01754386 0.05043244 0.         1.        ]\n",
      " ...\n",
      " [0.41385135 0.47727273 0.07017544 0.06427045 0.5        0.        ]\n",
      " [0.80405405 0.93181818 0.         0.01258764 0.5        0.        ]\n",
      " [0.9847973  1.         0.38596491 0.25139918 0.75       0.        ]]\n",
      "\n",
      "\n",
      "[[0.85472973 0.95454545 0.14035088 0.14993508 0.         0.5       ]\n",
      " [0.69425676 0.79545455 0.12280702 0.23787077 0.75       0.5       ]\n",
      " [0.1097973  0.11363636 0.03508772 0.04596824 0.75       0.5       ]\n",
      " ...\n",
      " [0.07263514 0.06818182 0.05263158 0.0740757  0.75       1.        ]\n",
      " [0.62668919 0.70454545 0.         0.00288026 0.75       0.        ]\n",
      " [0.82939189 0.93181818 0.03508772 0.06728253 0.5        0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# feature scale the X_train and X_test values\n",
    "\n",
    "norm = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# transform training data\n",
    "X_train = norm.transform(X_train)\n",
    "\n",
    "# transform testing data\n",
    "X_test = norm.transform(X_test)\n",
    "\n",
    "print(X_train)\n",
    "print('\\n')\n",
    "print(X_test)\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Train_Score</th>\n",
       "      <th>R_squared</th>\n",
       "      <th>Mean_absolute_error</th>\n",
       "      <th>Root_mean_sqd_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost_model</td>\n",
       "      <td>0.908240</td>\n",
       "      <td>0.880619</td>\n",
       "      <td>30993.313013</td>\n",
       "      <td>48903.996996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf_model</td>\n",
       "      <td>0.885372</td>\n",
       "      <td>0.856261</td>\n",
       "      <td>32447.815176</td>\n",
       "      <td>53661.730446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lgbm_model</td>\n",
       "      <td>0.854370</td>\n",
       "      <td>0.844469</td>\n",
       "      <td>36318.839399</td>\n",
       "      <td>55819.325641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ridge_model</td>\n",
       "      <td>0.450127</td>\n",
       "      <td>0.433038</td>\n",
       "      <td>74466.377762</td>\n",
       "      <td>106574.598803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear_model</td>\n",
       "      <td>0.450130</td>\n",
       "      <td>0.432941</td>\n",
       "      <td>74456.266741</td>\n",
       "      <td>106583.705446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name  Train_Score  R_squared  Mean_absolute_error  \\\n",
       "3  xgboost_model     0.908240   0.880619         30993.313013   \n",
       "2       rf_model     0.885372   0.856261         32447.815176   \n",
       "1     lgbm_model     0.854370   0.844469         36318.839399   \n",
       "4    ridge_model     0.450127   0.433038         74466.377762   \n",
       "0   linear_model     0.450130   0.432941         74456.266741   \n",
       "\n",
       "   Root_mean_sqd_error  \n",
       "3         48903.996996  \n",
       "2         53661.730446  \n",
       "1         55819.325641  \n",
       "4        106574.598803  \n",
       "0        106583.705446  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    'linear_model': LinearRegression(),\n",
    "    'lgbm_model':LGBMRegressor(random_state = 123),\n",
    "    'rf_model': RandomForestRegressor(\n",
    "        random_state=123,\n",
    "        n_estimators=200,\n",
    "        max_depth=12,\n",
    "        min_samples_leaf=5 \n",
    "    ),\n",
    "    \n",
    "    'xgboost_model': XGBRegressor(\n",
    "        random_state=123,\n",
    "        n_estimators=200,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        tree_method='hist' # Faster training\n",
    "    ),\n",
    "    \n",
    "    'ridge_model': Ridge(\n",
    "        random_state=123,\n",
    "        alpha=1.0          # Default regularization strength\n",
    "    )\n",
    "}\n",
    "\n",
    "def train_model(models: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    It takes in a dictionary containing a key-pair of model name and estimators.\n",
    "    It returns a data frame containing the metrics of the trained model.\n",
    "    \"\"\"\n",
    "    my_dict = {}\n",
    "    name_list, train_score_list, r_sqd_list, mae_list, rmse_list = [], [], [], [], []\n",
    "    for name, estimator in models.items():\n",
    "        # fit\n",
    "        estimator.fit(X_train, y_train)\n",
    "\n",
    "        # make predictions\n",
    "        y_pred = estimator.predict(X_test)\n",
    "\n",
    "        # metrics\n",
    "        train_score = estimator.score(X_train, y_train)\n",
    "        r_sqd = metrics.r2_score(y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # add the metrics to the empty list\n",
    "        name_list.append(name)\n",
    "        train_score_list.append(train_score)\n",
    "        r_sqd_list.append(r_sqd)\n",
    "        mae_list.append(mae)\n",
    "        rmse_list.append(rmse)\n",
    "\n",
    "    my_dict[\"Name\"] = name_list\n",
    "    my_dict[\"Train_Score\"] = train_score_list\n",
    "    my_dict[\"R_squared\"] = r_sqd_list\n",
    "    my_dict[\"Mean_absolute_error\"] = mae_list\n",
    "    my_dict[\"Root_mean_sqd_error\"] = rmse_list\n",
    "\n",
    "    my_dataframe = pd.DataFrame(my_dict)\n",
    "    my_dataframe = my_dataframe.sort_values(\"Root_mean_sqd_error\")\n",
    "    return my_dataframe\n",
    "\n",
    "train_model(models)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {\n",
    "#     'colsample_bytree': [0.6,0.7,0.8],\n",
    "#     'learning_rate': [0.01,0.05,0.1],\n",
    "#     'max_depth': [9,12,14],\n",
    "#     'min_child_weight': [0.01,0.05,0.1],\n",
    "#     'n_estimators': [150,250 ,350],\n",
    "#     'subsample': [0.8,0.7,0.9],\n",
    "# }\n",
    "\n",
    "\n",
    "# model = GridSearchCV(\n",
    "#     estimator=XGBRegressor(\n",
    "#         random_state=123,\n",
    "#         tree_method='hist'  # Keep the fast training method\n",
    "#     ),\n",
    "#     param_grid=grid,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     cv=5,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1  # Use all available cores\n",
    "# )\n",
    "\n",
    "# best 0.7 , 0.1, 9, 0.1 , 350, 0.8 \n",
    "# grid = {\n",
    "#     'colsample_bytree': [0.7],\n",
    "#     'learning_rate': [0.1],\n",
    "#     'max_depth': [9],\n",
    "#     'min_child_weight': [0.1],\n",
    "#     'n_estimators': [350],\n",
    "#     'subsample': [0.8],\n",
    "# }\n",
    "\n",
    "\n",
    "# model = GridSearchCV(\n",
    "#     estimator=XGBRegressor(\n",
    "#         random_state=123,\n",
    "#         tree_method='hist'  # Keep the fast training method\n",
    "#     ),\n",
    "#     param_grid=grid,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     cv=5,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1  # Use all available cores\n",
    "# )\n",
    "\n",
    "# grid = {\n",
    "#     'colsample_bytree': [0.6,0.7,0.8],\n",
    "#     'learning_rate': [0.01,0.05,0.1],\n",
    "#     'max_depth': [9,12,14],\n",
    "#     'min_child_weight': [0.01,0.05,0.1],\n",
    "#     'n_estimators': [150,250 ,350],\n",
    "#     'subsample': [0.8,0.7,0.9],\n",
    "# }\n",
    "\n",
    "\n",
    "# model = GridSearchCV(\n",
    "#     estimator=XGBRegressor(\n",
    "#         random_state=123,\n",
    "#         tree_method='hist'  # Keep the fast training method\n",
    "#     ),\n",
    "#     param_grid=grid,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     cv=5,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1  # Use all available cores\n",
    "# )\n",
    "\n",
    "# grid = {\n",
    "#     'colsample_bytree': [0.6, 0.7, 0.8],  # Fraction of features to be used for each tree\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],   # Step size shrinkage used to prevent overfitting\n",
    "#     'max_depth': [9, 12, 14],             # Maximum depth of a tree\n",
    "#     'min_child_weight': [1, 5, 10],       # Minimum sum of instance weight (hessian) needed in a child\n",
    "#     'n_estimators': [150, 250, 350],      # Number of boosting rounds\n",
    "#     'subsample': [0.7, 0.8, 0.9],         # Fraction of samples to be used for each tree\n",
    "#     'gamma': [0, 0.1, 0.2],               # Minimum loss reduction required to make a further partition on a leaf node\n",
    "#     'reg_alpha': [0, 0.01, 0.1],          # L1 regularization term on weights\n",
    "#     'reg_lambda': [1, 1.5, 2]             # L2 regularization term on weights\n",
    "# }\n",
    "\n",
    "# model = GridSearchCV(\n",
    "#     estimator=XGBRegressor(\n",
    "#         random_state=123,\n",
    "#         tree_method='hist'  # Keep the fast training method\n",
    "#     ),\n",
    "#     param_grid=grid,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     cv=5,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1 \n",
    "# )\n",
    "grid = {\n",
    "    'colsample_bytree': [0.7],  # Fraction of features to be used for each tree\n",
    "    'learning_rate': [0.1],   # Step size shrinkage used to prevent overfitting\n",
    "    'max_depth': [9],             # Maximum depth of a tree\n",
    "    'min_child_weight': [1],       # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'n_estimators': [350],      # Number of boosting rounds\n",
    "    'subsample': [0.8],         # Fraction of samples to be used for each tree\n",
    "    'gamma': [0],               # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    'reg_alpha': [0.1],          # L1 regularization term on weights\n",
    "    'reg_lambda': [1.5]             # L2 regularization term on weights\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=XGBRegressor(\n",
    "        random_state=123,\n",
    "        tree_method='hist'  # Keep the fast training method\n",
    "    ),\n",
    "    param_grid=grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1 \n",
    ")\n",
    "# Best parameters: {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 350, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=123, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.7], &#x27;gamma&#x27;: [0],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [9],\n",
       "                         &#x27;min_child_weight&#x27;: [1], &#x27;n_estimators&#x27;: [350],\n",
       "                         &#x27;reg_alpha&#x27;: [0.1], &#x27;reg_lambda&#x27;: [1.5],\n",
       "                         &#x27;subsample&#x27;: [0.8]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=123, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.7], &#x27;gamma&#x27;: [0],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [9],\n",
       "                         &#x27;min_child_weight&#x27;: [1], &#x27;n_estimators&#x27;: [350],\n",
       "                         &#x27;reg_alpha&#x27;: [0.1], &#x27;reg_lambda&#x27;: [1.5],\n",
       "                         &#x27;subsample&#x27;: [0.8]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=123, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=123, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=123, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.7], 'gamma': [0],\n",
       "                         'learning_rate': [0.1], 'max_depth': [9],\n",
       "                         'min_child_weight': [1], 'n_estimators': [350],\n",
       "                         'reg_alpha': [0.1], 'reg_lambda': [1.5],\n",
       "                         'subsample': [0.8]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 350, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.8}\n",
      "\n",
      "Prediction Metrics:\n",
      "R-squared Score: 0.8978823187678526\n",
      "Mean Absolute Error: 27792.53282807005\n",
      "Root Mean Squared Error: 45230.05728960372\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r_squared</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGboost</td>\n",
       "      <td>0.897882</td>\n",
       "      <td>27792.532828</td>\n",
       "      <td>45230.05729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  r_squared           mae         rmse\n",
       "0  XGboost   0.897882  27792.532828  45230.05729"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Best parameters:\", model.best_params_)\n",
    "print(\"\\nPrediction Metrics:\")\n",
    "print(\"R-squared Score:\", metrics.r2_score(y_test, y_pred))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# %%\n",
    "grid_model = pd.DataFrame({\n",
    "    'model': ['XGboost'],\n",
    "    'r_squared': [metrics.r2_score(y_test, y_pred)],\n",
    "    'mae': [mean_absolute_error(y_test, y_pred)],\n",
    "    'rmse': [np.sqrt(metrics.mean_squared_error(y_test, y_pred))]\n",
    "    })\n",
    "grid_model\n",
    "\n",
    "\n",
    "# # %%\n",
    "# data = {\"model\": model, \"normalization\": norm}\n",
    "# with open('../models/regressor3.pkl', 'wb') as file:\n",
    "#     pickle.dump(data, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "        feature  importance\n",
      "2           age    0.300223\n",
      "5  transmission    0.292134\n",
      "1  manufacturer    0.133431\n",
      "0          name    0.122963\n",
      "4        engine    0.090465\n",
      "3  kilometerage    0.060784\n",
      "\n",
      "Predictions:\n",
      "                     Car   Manufacturer  Age Mileage  Engine Transmission  \\\n",
      "0  Mercedes-Benz C Class  MERCEDES-BENZ    5  50,000  Petrol    Automatic   \n",
      "1         Toyota Corolla         TOYOTA    5  50,000  Petrol       Manual   \n",
      "2                 Bmw X5            BMW    5  50,000  Diesel    Automatic   \n",
      "3          Dacia Sandero          DACIA    5  50,000  Petrol       Manual   \n",
      "4            Ford Fiesta           FORD    5  50,000  Petrol       Manual   \n",
      "5                Audi A5           AUDI    5  50,000  Diesel    Automatic   \n",
      "\n",
      "  Estimated Price  \n",
      "0     329,492 MAD  \n",
      "1     138,938 MAD  \n",
      "2     463,164 MAD  \n",
      "3     118,575 MAD  \n",
      "4     120,329 MAD  \n",
      "5     235,272 MAD  \n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# #### Make Predictions on new data.\n",
    "\n",
    "# %%\n",
    "# Create test configurations using exact names from dataset\n",
    "data = pd.read_csv('../dataSet/cleaned_car_data2.csv')\n",
    "\n",
    "test_configurations = [\n",
    "    ['Mercedes-Benz C Class', 'MERCEDES-BENZ', 5, 50000.0, 'Petrol', 'Automatic'],  # Luxury newer car\n",
    "    ['Toyota Corolla', 'TOYOTA', 5, 50000.0, 'Petrol', 'Manual'],     # Economy newer car\n",
    "    ['Bmw X5', 'BMW', 5, 50000.0, 'Diesel', 'Automatic'],            # Luxury SUV\n",
    "    ['Dacia Sandero', 'DACIA', 5, 50000.0, 'Petrol', 'Manual'],      # Budget car\n",
    "    ['Ford Fiesta', 'FORD', 5, 50000.0, 'Petrol', 'Manual'],         # Popular economy car\n",
    "    ['Audi A5', 'AUDI', 5, 50000.0, 'Diesel', 'Automatic']           # Premium car\n",
    "]\n",
    "\n",
    "# Use the rest of the corrected code I provided earlier with these test configurations\n",
    "# Fit the label encoders once with the training data\n",
    "le_name.fit(data['name'])\n",
    "le_manufacturer.fit(data['manufacturer'])\n",
    "le_engine.fit(data['engine'])\n",
    "le_transmission.fit(data['transmission'])\n",
    "\n",
    "results = []\n",
    "for config in test_configurations:\n",
    "    try:\n",
    "        # Create numpy array with the right shape\n",
    "        new_data = np.zeros((1, 6))\n",
    "        \n",
    "        try:\n",
    "            # Transform each feature using the appropriate encoder\n",
    "            new_data[0, 0] = le_name.transform([config[0]])[0]  # Changed from fit_transform\n",
    "            new_data[0, 1] = le_manufacturer.transform([config[1]])[0]\n",
    "            new_data[0, 2] = float(config[2])  # age\n",
    "            new_data[0, 3] = float(config[3])  # kilometerage\n",
    "            new_data[0, 4] = le_engine.transform([config[4]])[0]\n",
    "            new_data[0, 5] = le_transmission.transform([config[5]])[0]\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Unknown category in {config[0]}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "        # Normalize using the same scaler used during training\n",
    "        normalized_data = norm.transform(new_data)\n",
    "        \n",
    "        # Predict (removed the *10 multiplication)\n",
    "        price = model.predict(normalized_data)\n",
    "        \n",
    "        results.append({\n",
    "            'Car': config[0],\n",
    "            'Manufacturer': config[1],\n",
    "            'Age': config[2],\n",
    "            'Mileage': f\"{config[3]:,.0f}\",\n",
    "            'Engine': config[4],\n",
    "            'Transmission': config[5],\n",
    "            'Estimated Price': f\"{price[0]:,.0f} MAD\"  # Removed *10\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing configuration {config}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Display results\n",
    "print(\"\\nFeature Importance:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': ['name', 'manufacturer', 'age', 'kilometerage', 'engine', 'transmission'],\n",
    "    'importance': model.best_estimator_.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feature_importance)\n",
    "print(\"\\nPredictions:\")\n",
    "result_df = pd.DataFrame(results)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "R-squared Score: 0.9445242869575412\n",
      "Mean Absolute Error: 21615.355905816406\n",
      "Root Mean Squared Error: 33494.02286236115\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r_squared</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGboost</td>\n",
       "      <td>0.944524</td>\n",
       "      <td>21615.355906</td>\n",
       "      <td>33494.022862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  r_squared           mae          rmse\n",
       "0  XGboost   0.944524  21615.355906  33494.022862"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine training and test data\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.concatenate((y_train, y_test))\n",
    "\n",
    "# Fit the model on the combined dataset\n",
    "model.fit(X_combined, y_combined, verbose=1)\n",
    "\n",
    "# Make predictions on the combined dataset\n",
    "y_pred_combined = model.predict(X_combined)\n",
    "\n",
    "# Evaluate the model on the combined dataset\n",
    "print(\"R-squared Score:\", metrics.r2_score(y_combined, y_pred_combined))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_combined, y_pred_combined))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_combined, y_pred_combined)))\n",
    "grid_model = pd.DataFrame({\n",
    "    'model': ['XGboost'],\n",
    "    'r_squared': [metrics.r2_score(y_combined, y_pred_combined)],\n",
    "    'mae': [mean_absolute_error(y_combined, y_pred_combined)],\n",
    "    'rmse': [np.sqrt(metrics.mean_squared_error(y_combined, y_pred_combined))]\n",
    "    })\n",
    "grid_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "        feature  importance\n",
      "2           age    0.329431\n",
      "5  transmission    0.241670\n",
      "1  manufacturer    0.179594\n",
      "0          name    0.112557\n",
      "4        engine    0.075778\n",
      "3  kilometerage    0.060969\n",
      "\n",
      "Predictions:\n",
      "                     Car   Manufacturer  Age Mileage  Engine Transmission  \\\n",
      "0  Mercedes-Benz C Class  MERCEDES-BENZ    5  50,000  Petrol    Automatic   \n",
      "1         Toyota Corolla         TOYOTA    5  50,000  Petrol       Manual   \n",
      "2                 Bmw X5            BMW    5  50,000  Diesel    Automatic   \n",
      "3          Dacia Sandero          DACIA    5  50,000  Petrol       Manual   \n",
      "4            Ford Fiesta           FORD    5  50,000  Petrol       Manual   \n",
      "5                Audi A5           AUDI    5  50,000  Diesel    Automatic   \n",
      "\n",
      "  Estimated Price  \n",
      "0     295,195 MAD  \n",
      "1     128,416 MAD  \n",
      "2     437,590 MAD  \n",
      "3     119,119 MAD  \n",
      "4     123,987 MAD  \n",
      "5     225,432 MAD  \n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# #### Make Predictions on new data.\n",
    "\n",
    "# %%\n",
    "# Create test configurations using exact names from dataset\n",
    "data = pd.read_csv('../dataSet/cleaned_car_data2.csv')\n",
    "\n",
    "test_configurations = [\n",
    "    ['Mercedes-Benz C Class', 'MERCEDES-BENZ', 5, 50000.0, 'Petrol', 'Automatic'],  # Luxury newer car\n",
    "    ['Toyota Corolla', 'TOYOTA', 5, 50000.0, 'Petrol', 'Manual'],     # Economy newer car\n",
    "    ['Bmw X5', 'BMW', 5, 50000.0, 'Diesel', 'Automatic'],            # Luxury SUV\n",
    "    ['Dacia Sandero', 'DACIA', 5, 50000.0, 'Petrol', 'Manual'],      # Budget car\n",
    "    ['Ford Fiesta', 'FORD', 5, 50000.0, 'Petrol', 'Manual'],         # Popular economy car\n",
    "    ['Audi A5', 'AUDI', 5, 50000.0, 'Diesel', 'Automatic']           # Premium car\n",
    "]\n",
    "\n",
    "# Use the rest of the corrected code I provided earlier with these test configurations\n",
    "# Fit the label encoders once with the training data\n",
    "le_name.fit(data['name'])\n",
    "le_manufacturer.fit(data['manufacturer'])\n",
    "le_engine.fit(data['engine'])\n",
    "le_transmission.fit(data['transmission'])\n",
    "\n",
    "results = []\n",
    "for config in test_configurations:\n",
    "    try:\n",
    "        # Create numpy array with the right shape\n",
    "        new_data = np.zeros((1, 6))\n",
    "        \n",
    "        try:\n",
    "            # Transform each feature using the appropriate encoder\n",
    "            new_data[0, 0] = le_name.transform([config[0]])[0]  # Changed from fit_transform\n",
    "            new_data[0, 1] = le_manufacturer.transform([config[1]])[0]\n",
    "            new_data[0, 2] = float(config[2])  # age\n",
    "            new_data[0, 3] = float(config[3])  # kilometerage\n",
    "            new_data[0, 4] = le_engine.transform([config[4]])[0]\n",
    "            new_data[0, 5] = le_transmission.transform([config[5]])[0]\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Unknown category in {config[0]}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "        # Normalize using the same scaler used during training\n",
    "        normalized_data = norm.transform(new_data)\n",
    "        \n",
    "        # Predict (removed the *10 multiplication)\n",
    "        price = model.predict(normalized_data)\n",
    "        \n",
    "        results.append({\n",
    "            'Car': config[0],\n",
    "            'Manufacturer': config[1],\n",
    "            'Age': config[2],\n",
    "            'Mileage': f\"{config[3]:,.0f}\",\n",
    "            'Engine': config[4],\n",
    "            'Transmission': config[5],\n",
    "            'Estimated Price': f\"{price[0]:,.0f} MAD\"  # Removed *10\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing configuration {config}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Display results\n",
    "print(\"\\nFeature Importance:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': ['name', 'manufacturer', 'age', 'kilometerage', 'engine', 'transmission'],\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feature_importance)\n",
    "print(\"\\nPredictions:\")\n",
    "result_df = pd.DataFrame(results)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "The Car Price Prediction Project aims to develop a machine learning application that accurately predicts the prices of used cars based on various features such as manufacturer, engine type, transmission, mileage, price, and age. This project involves data scraping from the AA Cars website, comprehensive data cleaning and preprocessing, exploratory data analysis, and the implementation of multiple machine learning models. The final model, trained on a combined dataset, demonstrates a slight performance improvement over individual datasets. The project also includes an interactive web interface built with Flask, allowing users to input car details and receive price predictions and recommendations for similar cars. This paper presents the methodology, model evaluation, and results, highlighting the effectiveness of the chosen approach in predicting car prices and providing recommendations.\n",
    "\n",
    "### Introduction\n",
    "The used car market is a dynamic and complex industry where accurate pricing is crucial for both buyers and sellers. Predicting the price of a used car involves considering various factors such as the car's manufacturer, engine type, transmission, mileage, price, and age. Traditional methods of car price estimation often rely on expert knowledge and manual assessments, which can be subjective and inconsistent. With the advent of machine learning, it is possible to develop models that can predict car prices more accurately and consistently.\n",
    "\n",
    "This research paper presents the Car Price Prediction Project, which aims to leverage machine learning techniques to predict the prices of used cars and recommend similar cars based on input features. The project involves several key steps: data scraping from the AA Cars website, data cleaning and preprocessing, exploratory data analysis, and the implementation and evaluation of multiple machine learning models. The final model, trained on a combined dataset, shows a slight performance improvement, indicating the effectiveness of the chosen approach.\n",
    "\n",
    "The paper is structured as follows: Section 2 reviews related work in the field of car price prediction and machine learning models. Section 3 describes the methodology, including data collection, preprocessing, feature engineering, model training, and the recommendation system. Section 4 presents the results, including model evaluation and comparison. Section 5 discusses the limitations of the approach and potential future work. Finally, Section 6 concludes the paper by summarizing the key findings and contributions.\n",
    "\n",
    "By developing an accurate and reliable car price prediction model and a recommendation system, this project aims to provide valuable insights and tools for both buyers and sellers in the used car market, ultimately contributing to more informed decision-making and fairer pricing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Works\n",
    "\n",
    "Research on estimating the price of used cars is relatively recent and not extensively covered. In her MSc thesis, Listiani [3] demonstrated that a regression model using support vector machines (SVM) can predict the residual price of leased cars more accurately than simple multiple regression or multivariate regression. SVMs are particularly effective in handling high-dimensional data (numerous features used to predict the price) and can avoid both overfitting and underfitting. She employed a genetic algorithm to optimize the SVM parameters efficiently. However, the study did not express the improvement of SVM regression over simple regression in straightforward measures like mean deviation or variance.\n",
    "\n",
    "In another university thesis, Richardson [4] explored the hypothesis that car manufacturers aim to produce vehicles that do not depreciate quickly. Using multiple regression analysis, he found that hybrid cars (vehicles with both an internal combustion engine and an electric motor) retain their value better than traditional vehicles. This is likely due to increased environmental concerns and higher fuel efficiency. The study also considered other factors such as age, mileage, make, and MPG (miles per gallon). Data for this study was collected from various websites.\n",
    "\n",
    "Wu et al. [5] utilized a neuro-fuzzy knowledge-based system to predict the price of used cars, considering only three factors: the make of the car, the year of manufacture, and the engine style. The proposed system produced results comparable to simple regression methods. In the USA, car dealers sell hundreds of thousands of cars annually through leasing. Most of these cars are returned at the end of the leasing period and must be resold. Accurately pricing these cars is crucial for economic success. To address this, Du et al. [6] developed the ODAV (Optimal Distribution of Auction Vehicles) system, which not only estimates the best resale price but also advises on the optimal location to sell the car. Given the vast size of the United States, the selling location significantly impacts the price of used cars. A k-nearest neighbor regression model was used for price forecasting. Since its inception in 2003, the system has distributed over two million vehicles.\n",
    "\n",
    "Gonggi [7] proposed a model based on artificial neural networks to forecast the residual value of private used cars. The study focused on features such as mileage, manufacturer, and estimated useful life. The model was optimized to handle nonlinear relationships, which simple linear regression methods cannot manage. The model proved to be reasonably accurate in predicting the residual value of used cars.\n",
    "\n",
    "In a study by Sameerchand Pudaruth [8], supervised machine learning techniques were applied to predict the price of used cars in Mauritius. The predictions were based on historical data collected from daily newspapers. Various techniques, including multiple linear regression analysis, k-nearest neighbors, naïve Bayes, and decision trees, were used to make the predictions. The predictions were evaluated and compared to identify the best-performing methods. The study concluded that predicting the price of used cars is a challenging problem that requires sophisticated algorithms for high accuracy. All four methods provided comparable performance.\n",
    "\n",
    "Inspired by the study conducted by Sameerchand Pudaruth [8], this research explores the application of machine learning techniques to predict the price of used cars. These studies illustrate the diverse approaches and techniques used in predicting the price of used cars, such as support vector machines, multiple regression analysis, neuro-fuzzy systems, k-nearest neighbor regression, and artificial neural networks. Each method has its advantages and limitations, and the choice of method depends on the specific requirements and constraints of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "Despite the promising results obtained from the Car Price Prediction Project, several limitations need to be acknowledged:\n",
    "\n",
    "1. **Data Quality and Availability**:\n",
    "   - The accuracy of the predictions heavily depends on the quality and completeness of the data. The data scraped from the AA Cars website may contain inaccuracies, missing values, or inconsistencies that could affect the model's performance.\n",
    "   - The dataset used in this project may not be representative of the entire used car market, as it is limited to the listings available on a single website. This could lead to biased predictions that do not generalize well to other datasets or markets.\n",
    "\n",
    "2. **Geographical and Currency Limitations**:\n",
    "   - The data was scraped from the AA Cars website, which primarily serves the UK market. However, the project aims to predict car prices for Moroccan users. Although we converted prices from GBP to MAD by multiplying by 12.8, other regional factors influencing car prices in Morocco may not be captured.\n",
    "   - Differences in market dynamics, consumer preferences, and economic conditions between the UK and Morocco could impact the accuracy and relevance of the predictions.\n",
    "\n",
    "3. **Feature Limitations**:\n",
    "   - The features used in the model, such as manufacturer, engine type, transmission, mileage, price, and age, may not capture all the factors influencing a car's price. Other important factors, such as the car's condition, service history, and market demand, were not included due to data unavailability.\n",
    "   - The model does not account for external factors such as economic conditions, seasonal trends, or regional variations, which can significantly impact car prices.\n",
    "\n",
    "4. **Model Complexity and Interpretability**:\n",
    "   - While complex models like XGBoost and CatBoost can achieve high accuracy, they are often less interpretable than simpler models like linear regression. This can make it challenging to understand the model's decision-making process and explain the predictions to end-users.\n",
    "   - The recommendation system based on K-Nearest Neighbors (KNN) may not scale well with large datasets, as the computational complexity increases with the number of data points.\n",
    "\n",
    "5. **Hyperparameter Tuning**:\n",
    "   - Hyperparameter tuning was performed using GridSearchCV, which can be computationally expensive and time-consuming. More advanced techniques like Bayesian optimization or random search could potentially yield better results with less computational effort.\n",
    "   - The optimal hyperparameters found during tuning may not be universally applicable to all datasets or markets, limiting the model's generalizability.\n",
    "\n",
    "6. **Deployment and Maintenance**:\n",
    "   - The deployment of the web application on Azure Web App ensures accessibility, but it also introduces challenges related to scalability, security, and maintenance. Ensuring the application can handle high traffic and remains secure against potential threats requires ongoing effort.\n",
    "   - Regular updates to the model and data are necessary to maintain the accuracy and relevance of the predictions. This involves continuous monitoring, retraining, and validation of the model as new data becomes available.\n",
    "\n",
    "7. **User Interaction and Experience**:\n",
    "   - The web interface built with Flask provides a user-friendly way to input car details and receive predictions, but it may not cater to all user needs or preferences. Enhancing the user experience with additional features, such as interactive visualizations or personalized recommendations, could improve user satisfaction.\n",
    "   - The recommendation system suggests similar cars based on input features, but it may not always align with user preferences or expectations. Incorporating user feedback and preferences into the recommendation algorithm could enhance its relevance and usefulness.\n",
    "\n",
    "By acknowledging these limitations, we can identify areas for improvement and future work to enhance the accuracy, robustness, and usability of the Car Price Prediction Project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "Despite the promising results, several limitations need to be acknowledged:\n",
    "\n",
    "1. **Data Quality and Availability**:\n",
    "   - The accuracy of predictions depends on the quality of data scraped from the AA Cars website, which may contain inaccuracies or inconsistencies.\n",
    "   - The dataset may not represent the entire used car market, leading to biased predictions.\n",
    "\n",
    "2. **Geographical and Currency Limitations**:\n",
    "   - The data is from the UK market (AA Cars website), but the project targets Moroccan users. Prices were converted from GBP to MAD by multiplying by 12.8, but regional factors affecting car prices in Morocco may not be captured.\n",
    "   - Differences in market dynamics and economic conditions between the UK and Morocco could impact prediction accuracy.\n",
    "\n",
    "3. **Feature Limitations**:\n",
    "   - Important factors like car condition, service history, and market demand were not included due to data unavailability.\n",
    "   - External factors such as economic conditions and seasonal trends were not considered.\n",
    "\n",
    "4. **Model Complexity and Interpretability**:\n",
    "   - Complex models like XGBoost and CatBoost are less interpretable than simpler models, making it challenging to explain predictions.\n",
    "   - The KNN-based recommendation system may not scale well with large datasets.\n",
    "\n",
    "5. **Hyperparameter Tuning**:\n",
    "   - Hyperparameter tuning using GridSearchCV is computationally expensive and time-consuming. More advanced techniques could yield better results.\n",
    "   - Optimal hyperparameters may not be universally applicable, limiting generalizability.\n",
    "\n",
    "6. **Deployment and Maintenance**:\n",
    "   - Deployment on Azure Web App introduces challenges related to scalability, security, and maintenance.\n",
    "   - Regular updates to the model and data are necessary to maintain accuracy and relevance.\n",
    "\n",
    "7. **User Interaction and Experience**:\n",
    "   - The Flask web interface may not cater to all user needs. Enhancing the user experience with additional features could improve satisfaction.\n",
    "   - The recommendation system may not always align with user preferences. Incorporating user feedback could enhance its relevance.\n",
    "\n",
    "By acknowledging these limitations, we can identify areas for improvement and future work to enhance the Car Price Prediction Project's accuracy, robustness, and usability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The Car Price Prediction Project successfully demonstrates the application of machine learning techniques to predict the prices of used cars and recommend similar cars based on input features. By leveraging data scraped from the AA Cars website, comprehensive data cleaning and preprocessing, and the implementation of multiple machine learning models, the project achieved a slight performance improvement with the final model trained on a combined dataset.\n",
    "\n",
    "The project highlights the effectiveness of advanced machine learning models such as XGBoost and CatBoost in handling high-dimensional data and providing accurate predictions. Additionally, the K-Nearest Neighbors (KNN) algorithm proved useful in developing a recommendation system that suggests similar cars based on user input.\n",
    "\n",
    "Despite the promising results, several limitations were identified, including data quality and availability, geographical and currency differences, feature limitations, model complexity, and deployment challenges. Addressing these limitations in future work could further enhance the accuracy, robustness, and usability of the prediction and recommendation systems.\n",
    "\n",
    "The deployment of the web application using Flask and Azure Web App ensures accessibility and provides a user-friendly interface for users to input car details and receive predictions. However, ongoing maintenance and updates are necessary to keep the application relevant and accurate.\n",
    "\n",
    "In conclusion, this project provides valuable insights and tools for both buyers and sellers in the used car market, contributing to more informed decision-making and fairer pricing. Future work should focus on addressing the identified limitations, incorporating additional features, and exploring more sophisticated algorithms to further improve the system's performance and user experience."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
