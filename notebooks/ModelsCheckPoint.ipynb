{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # MODEL BUILDING\n",
    "\n",
    "# %% [markdown]\n",
    "# ## import the relevant libraries\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, mean_squared_error\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>kilometerage</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford Fiesta</td>\n",
       "      <td>FORD</td>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>175418.06</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vauxhall Corsa</td>\n",
       "      <td>VAUXHALL</td>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>175418.06</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vauxhall Zafira</td>\n",
       "      <td>VAUXHALL</td>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>175418.06</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peugeot 107</td>\n",
       "      <td>PEUGEOT</td>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>175418.06</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vauxhall Corsa</td>\n",
       "      <td>VAUXHALL</td>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>175418.06</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name manufacturer  year  age  kilometerage  engine transmission  \\\n",
       "0      Ford Fiesta         FORD  2003   22     175418.06  Petrol    Automatic   \n",
       "1   Vauxhall Corsa     VAUXHALL  2003   22     175418.06  Petrol    Automatic   \n",
       "2  Vauxhall Zafira     VAUXHALL  2003   22     175418.06  Petrol    Automatic   \n",
       "3      Peugeot 107      PEUGEOT  2003   22     175418.06  Petrol    Automatic   \n",
       "4   Vauxhall Corsa     VAUXHALL  2003   22     175418.06  Petrol    Automatic   \n",
       "\n",
       "   price  \n",
       "0   1500  \n",
       "1   1500  \n",
       "2   1500  \n",
       "3   1500  \n",
       "4   1500  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "data = pd.read_csv('../dataSet/cleaned_car_data2.csv')\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>age</th>\n",
       "      <th>kilometerage</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63968</th>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50404.52880</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>84995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63969</th>\n",
       "      <td>466</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>4184.28400</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>84995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63970</th>\n",
       "      <td>572</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>3057.74600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63971</th>\n",
       "      <td>398</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>12824.83046</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63972</th>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7903.46874</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  manufacturer  age  kilometerage  engine  transmission  price\n",
       "63968    63             4    5   50404.52880       3             0  84995\n",
       "63969   466            41    2    4184.28400       2             0  84995\n",
       "63970   572            43    2    3057.74600       0             0  84995\n",
       "63971   398            34    3   12824.83046       3             0  85000\n",
       "63972    79             5    1    7903.46874       2             0  85000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## drop the name and year columns because it is irrelevant in our model building\n",
    "\n",
    "# %%\n",
    "data = data.drop(['year'], axis=1)\n",
    "\n",
    "# %%\n",
    "data.head()\n",
    "\n",
    "# %%\n",
    "data['name'].unique()\n",
    "\n",
    "# %% [markdown]\n",
    "# # label encode the categorical values\n",
    "\n",
    "# %%\n",
    "le_name = LabelEncoder()\n",
    "le_manufacturer = LabelEncoder()\n",
    "le_engine = LabelEncoder()\n",
    "le_transmission = LabelEncoder()\n",
    "data['name'] = le_name.fit_transform(data['name'])\n",
    "data['manufacturer'] = le_manufacturer.fit_transform(data['manufacturer'])\n",
    "data['engine'] = le_engine.fit_transform(data['engine'])\n",
    "data['transmission'] = le_transmission.fit_transform(data['transmission'])\n",
    "\n",
    "# %%\n",
    "data.tail(\n",
    ")\n",
    "\n",
    "# %%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149 506 523 374  98 178 153 266 378 217  70 363 411 135  19 179 104 501\n",
      " 579 157 458 382 142 514 224 108 161 494 555 365 469 184 426 128 105 347\n",
      " 141 145 164 433 273 380 174 371 228 442 291 459 419  65 170 272 285 330\n",
      " 529 226 240  10 114 537  76 416 368 391 427 189 468 107 231 491 279 467\n",
      " 392 553   9   3 581 379 592 188 513  13 521 341 276  59 452 229 274 447\n",
      " 372 448 251 421 385 116 438 129 476 499  95 196 485 110 323 301 275 136\n",
      " 299 559 126 503 342 177 351 197 449 570 429 361 190 584 199  21 286 302\n",
      " 242 300 577 267  15 102 113 456 393 483 264 413 292 163 358 144 373 278\n",
      " 386 348 210 227  20 571 139 500 534 515 357 356 451 362 213 241 152  93\n",
      " 353 159 530 281 289 345 256  78 453 103 284 326 115 344 200  16 502   2\n",
      " 375 290 158 282 394 211 441 590 558 376 431 460 566 520 531 335 444 493\n",
      " 524 137 130 585 578 223 498 270 583 446 245 420 370 109 321 387 191 162\n",
      " 132 214 410 322 203 143 324 295 173   7 280 352 146  17 455 327 192 138\n",
      " 225 366  39 383 415 175 422 450 517 388 461 484 283 572 412 377 118  53\n",
      " 479 543  35  29 140 349 209 248  24 176  51 215 106 519  66 510 343 367\n",
      " 230  22 237 364 482 238 355 243 402 268 540 169   0 486  14 504 425 424\n",
      "  79  75  67 147  73 205 171  69 423 401 198 512 193 202 466 443 182 311\n",
      "  82 334 573  71 239 339 481 167 350 310 117 488 221 509 435 160 297 172\n",
      " 525 296  27 232 354 100 560 111 536 487 155 508 340 561  52 470 277 151\n",
      " 507 505 434 154 586 346  94 150 233  72 533 557 187 312 338 414 473 212\n",
      " 511 294 337 381 471 535 131 389 333 428   8 436 556 332 457 390 475 269\n",
      " 325 478 462 544  60 314 218 582 518 216  11 474 395 490 222 254  90  64\n",
      " 204  68 430 526 516 298 127 439 408 554 477 287  61 406  56  45 336   1\n",
      " 538 564 265  89  12 316 587  97 497 445   4 495 263 185 208 246 235 562\n",
      " 539 404 317 432 403 168 112 293 463 331 396 400  62 567 259  25 122 545\n",
      "  28  18 546 565  92 489 397 542 563 305 124 121 440 589 496 194  91  55\n",
      " 249 417 166 315 541 207  74 384 522  77 307 527 369 303  32 165 548  30\n",
      " 547 492 123 454 156 313 528 262 255 125 183 260  43 329  33 409 574 304\n",
      " 569 181  88 568 119  47  31 219 258 359  37 319  85 186 120 575 306 195\n",
      " 472 271 465 480 250 328 588 549 464 234 580 244  23  48 180 206 398 399\n",
      "  34  36   5 532  46  83  99   6  80 320 253  54  81 591  49 252  41 261\n",
      " 437  40  57 576 257 318  87 418 551  50 550 247 552 407  26 148  86 308\n",
      " 360 236 405  96 201 101  58  84 309  42  63 133 220 288 134  44  38]\n",
      "21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((51178, 6), (12795, 6), (51178,), (12795,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['name'].unique()) \n",
    "print(data[data['name'] == 1].shape[0])\n",
    "\n",
    "# %%\n",
    "# creating X and y variables\n",
    "X = data.drop(['price'], axis=1)\n",
    "y = data['price'] * 10\n",
    "X.head()\n",
    "y.head()\n",
    "\n",
    "# %%\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# %%\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55405405 0.61363636 0.0877193  0.19286702 0.         0.        ]\n",
      " [0.85472973 0.95454545 0.07017544 0.06140988 0.75       0.5       ]\n",
      " [0.51013514 0.61363636 0.01754386 0.05043235 0.         1.        ]\n",
      " ...\n",
      " [0.41385135 0.47727273 0.07017544 0.06427079 0.5        0.        ]\n",
      " [0.80405405 0.93181818 0.         0.012588   0.5        0.        ]\n",
      " [0.9847973  1.         0.38596491 0.25139992 0.75       0.        ]]\n",
      "\n",
      "\n",
      "[[0.85472973 0.95454545 0.14035088 0.1499341  0.         0.5       ]\n",
      " [0.69425676 0.79545455 0.12280702 0.23787007 0.75       0.5       ]\n",
      " [0.1097973  0.11363636 0.03508772 0.0459674  0.75       0.5       ]\n",
      " ...\n",
      " [0.07263514 0.06818182 0.05263158 0.07407503 0.75       1.        ]\n",
      " [0.62668919 0.70454545 0.         0.0028802  0.75       0.        ]\n",
      " [0.82939189 0.93181818 0.03508772 0.06728278 0.5        0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# feature scale the X_train and X_test values\n",
    "\n",
    "norm = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# transform training data\n",
    "X_train = norm.transform(X_train)\n",
    "\n",
    "# transform testing data\n",
    "X_test = norm.transform(X_test)\n",
    "\n",
    "print(X_train)\n",
    "print('\\n')\n",
    "print(X_test)\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m my_dataframe\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(models)\u001b[0m\n\u001b[0;32m     32\u001b[0m name_list, train_score_list, r_sqd_list, mae_list, rmse_list \u001b[38;5;241m=\u001b[39m [], [], [], [], []\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, estimator \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# fit\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# make predictions\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# models = {\n",
    "#     'linear_model': LinearRegression(),\n",
    "#     'lgbm_model':LGBMRegressor(random_state = 123),\n",
    "#     'rf_model': RandomForestRegressor(\n",
    "#         random_state=123,\n",
    "#         n_estimators=200,\n",
    "#         max_depth=12,\n",
    "#         min_samples_leaf=5 \n",
    "#     ),\n",
    "    \n",
    "#     'xgboost_model': XGBRegressor(\n",
    "#         random_state=123,\n",
    "#         n_estimators=200,\n",
    "#         max_depth=8,\n",
    "#         learning_rate=0.05,\n",
    "#         tree_method='hist' # Faster training\n",
    "#     ),\n",
    "    \n",
    "#     'ridge_model': Ridge(\n",
    "#         random_state=123,\n",
    "#         alpha=1.0          # Default regularization strength\n",
    "#     )\n",
    "#  }\n",
    "\n",
    "# # %%\n",
    "# def train_model(models: dict) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     It takes in a dictionary containing a key-pair of model name and estimators.\n",
    "#     It returns a data frame containing the metrics of the trained model.\n",
    "#     \"\"\"\n",
    "#     my_dict = {}\n",
    "#     name_list, train_score_list, r_sqd_list, mae_list, rmse_list = [], [], [], [], []\n",
    "#     for name, estimator in models.items():\n",
    "#         # fit\n",
    "#         estimator.fit(X_train, y_train)\n",
    "\n",
    "#         # make predictions\n",
    "#         y_pred = estimator.predict(X_test)\n",
    "\n",
    "#         # metrics\n",
    "#         train_score = estimator.score(X_train, y_train)\n",
    "#         r_sqd = metrics.r2_score(y_test, y_pred)\n",
    "#         mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "#         mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "#         rmse = np.sqrt(mse)\n",
    "\n",
    "#         # add the metrics to the empty list\n",
    "#         name_list.append(name)\n",
    "#         train_score_list.append(train_score)\n",
    "#         r_sqd_list.append(r_sqd)\n",
    "#         mae_list.append(mae)\n",
    "#         rmse_list.append(rmse)\n",
    "\n",
    "#     my_dict[\"Name\"] = name_list\n",
    "#     my_dict[\"Train_Score\"] = train_score_list\n",
    "#     my_dict[\"R_squared\"] = r_sqd_list\n",
    "#     my_dict[\"Mean_absolute_error\"] = mae_list\n",
    "#     my_dict[\"Root_mean_sqd_error\"] = rmse_list\n",
    "\n",
    "#     my_dataframe = pd.DataFrame(my_dict)\n",
    "#     my_dataframe = my_dataframe.sort_values(\"Root_mean_sqd_error\")\n",
    "#     return my_dataframe\n",
    "\n",
    "# # %%\n",
    "# train_model(models)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=123, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.7], &#x27;gamma&#x27;: [0, 0.1, 0.2],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [9],\n",
       "                         &#x27;min_child_weight&#x27;: [1], &#x27;n_estimators&#x27;: [350],\n",
       "                         &#x27;reg_alpha&#x27;: [0.1], &#x27;reg_lambda&#x27;: [1.5],\n",
       "                         &#x27;subsample&#x27;: [0.8]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=123, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.7], &#x27;gamma&#x27;: [0, 0.1, 0.2],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [9],\n",
       "                         &#x27;min_child_weight&#x27;: [1], &#x27;n_estimators&#x27;: [350],\n",
       "                         &#x27;reg_alpha&#x27;: [0.1], &#x27;reg_lambda&#x27;: [1.5],\n",
       "                         &#x27;subsample&#x27;: [0.8]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=123, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=123, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=123, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.7], 'gamma': [0, 0.1, 0.2],\n",
       "                         'learning_rate': [0.1], 'max_depth': [9],\n",
       "                         'min_child_weight': [1], 'n_estimators': [350],\n",
       "                         'reg_alpha': [0.1], 'reg_lambda': [1.5],\n",
       "                         'subsample': [0.8]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid = {\n",
    "#     'colsample_bytree': [0.6,0.7,0.8],\n",
    "#     'learning_rate': [0.01,0.05,0.1],\n",
    "#     'max_depth': [9,12,14],\n",
    "#     'min_child_weight': [0.01,0.05,0.1],\n",
    "#     'n_estimators': [150,250 ,350],\n",
    "#     'subsample': [0.8,0.7,0.9],\n",
    "# }\n",
    "\n",
    "\n",
    "# model = GridSearchCV(\n",
    "#     estimator=XGBRegressor(\n",
    "#         random_state=123,\n",
    "#         tree_method='hist'  # Keep the fast training method\n",
    "#     ),\n",
    "#     param_grid=grid,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     cv=5,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1  # Use all available cores\n",
    "# )\n",
    "\n",
    "# best 0.7 , 0.1, 9, 0.1 , 350, 0.8 \n",
    "# grid = {\n",
    "#     'colsample_bytree': [0.7],\n",
    "#     'learning_rate': [0.1],\n",
    "#     'max_depth': [9],\n",
    "#     'min_child_weight': [0.1],\n",
    "#     'n_estimators': [350],\n",
    "#     'subsample': [0.8],\n",
    "# }\n",
    "\n",
    "\n",
    "# model = GridSearchCV(\n",
    "#     estimator=XGBRegressor(\n",
    "#         random_state=123,\n",
    "#         tree_method='hist'  # Keep the fast training method\n",
    "#     ),\n",
    "#     param_grid=grid,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     cv=5,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1  # Use all available cores\n",
    "# )\n",
    "\n",
    "# grid = {\n",
    "#     'colsample_bytree': [0.6,0.7,0.8],\n",
    "#     'learning_rate': [0.01,0.05,0.1],\n",
    "#     'max_depth': [9,12,14],\n",
    "#     'min_child_weight': [0.01,0.05,0.1],\n",
    "#     'n_estimators': [150,250 ,350],\n",
    "#     'subsample': [0.8,0.7,0.9],\n",
    "# }\n",
    "\n",
    "\n",
    "# model = GridSearchCV(\n",
    "#     estimator=XGBRegressor(\n",
    "#         random_state=123,\n",
    "#         tree_method='hist'  # Keep the fast training method\n",
    "#     ),\n",
    "#     param_grid=grid,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     cv=5,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1  # Use all available cores\n",
    "# )\n",
    "\n",
    "# grid = {\n",
    "#     'colsample_bytree': [0.6, 0.7, 0.8],  # Fraction of features to be used for each tree\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],   # Step size shrinkage used to prevent overfitting\n",
    "#     'max_depth': [9, 12, 14],             # Maximum depth of a tree\n",
    "#     'min_child_weight': [1, 5, 10],       # Minimum sum of instance weight (hessian) needed in a child\n",
    "#     'n_estimators': [150, 250, 350],      # Number of boosting rounds\n",
    "#     'subsample': [0.7, 0.8, 0.9],         # Fraction of samples to be used for each tree\n",
    "#     'gamma': [0, 0.1, 0.2],               # Minimum loss reduction required to make a further partition on a leaf node\n",
    "#     'reg_alpha': [0, 0.01, 0.1],          # L1 regularization term on weights\n",
    "#     'reg_lambda': [1, 1.5, 2]             # L2 regularization term on weights\n",
    "# }\n",
    "\n",
    "# model = GridSearchCV(\n",
    "#     estimator=XGBRegressor(\n",
    "#         random_state=123,\n",
    "#         tree_method='hist'  # Keep the fast training method\n",
    "#     ),\n",
    "#     param_grid=grid,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     cv=5,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1 \n",
    "# )\n",
    "grid = {\n",
    "    'colsample_bytree': [0.7],  # Fraction of features to be used for each tree\n",
    "    'learning_rate': [0.1],   # Step size shrinkage used to prevent overfitting\n",
    "    'max_depth': [9],             # Maximum depth of a tree\n",
    "    'min_child_weight': [1],       # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'n_estimators': [350],      # Number of boosting rounds\n",
    "    'subsample': [0.8],         # Fraction of samples to be used for each tree\n",
    "    'gamma': [0],               # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    'reg_alpha': [0.1],          # L1 regularization term on weights\n",
    "    'reg_lambda': [1.5]             # L2 regularization term on weights\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=XGBRegressor(\n",
    "        random_state=123,\n",
    "        tree_method='hist'  # Keep the fast training method\n",
    "    ),\n",
    "    param_grid=grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1 \n",
    ")\n",
    "# Best parameters: {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 350, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 350, 'reg_alpha': 0.1, 'reg_lambda': 1.5, 'subsample': 0.8}\n",
      "\n",
      "Prediction Metrics:\n",
      "R-squared Score: 0.8978823187678526\n",
      "Mean Absolute Error: 27792.53282807005\n",
      "Root Mean Squared Error: 45230.05728960372\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r_squared</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGboost</td>\n",
       "      <td>0.897882</td>\n",
       "      <td>27792.532828</td>\n",
       "      <td>45230.05729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  r_squared           mae         rmse\n",
       "0  XGboost   0.897882  27792.532828  45230.05729"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Best parameters:\", model.best_params_)\n",
    "print(\"\\nPrediction Metrics:\")\n",
    "print(\"R-squared Score:\", metrics.r2_score(y_test, y_pred))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# %%\n",
    "grid_model = pd.DataFrame({\n",
    "    'model': ['XGboost'],\n",
    "    'r_squared': [metrics.r2_score(y_test, y_pred)],\n",
    "    'mae': [mean_absolute_error(y_test, y_pred)],\n",
    "    'rmse': [np.sqrt(metrics.mean_squared_error(y_test, y_pred))]\n",
    "    })\n",
    "grid_model\n",
    "\n",
    "\n",
    "# # %%\n",
    "# data = {\"model\": model, \"normalization\": norm}\n",
    "# with open('../models/regressor3.pkl', 'wb') as file:\n",
    "#     pickle.dump(data, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "        feature  importance\n",
      "2           age    0.300223\n",
      "5  transmission    0.292134\n",
      "1  manufacturer    0.133431\n",
      "0          name    0.122963\n",
      "4        engine    0.090465\n",
      "3  kilometerage    0.060784\n",
      "\n",
      "Predictions:\n",
      "                     Car   Manufacturer  Age Mileage  Engine Transmission  \\\n",
      "0  Mercedes-Benz C Class  MERCEDES-BENZ    5  50,000  Petrol    Automatic   \n",
      "1         Toyota Corolla         TOYOTA    5  50,000  Petrol       Manual   \n",
      "2                 Bmw X5            BMW    5  50,000  Diesel    Automatic   \n",
      "3          Dacia Sandero          DACIA    5  50,000  Petrol       Manual   \n",
      "4            Ford Fiesta           FORD    5  50,000  Petrol       Manual   \n",
      "5                Audi A5           AUDI    5  50,000  Diesel    Automatic   \n",
      "\n",
      "  Estimated Price  \n",
      "0     329,492 MAD  \n",
      "1     138,938 MAD  \n",
      "2     463,164 MAD  \n",
      "3     118,575 MAD  \n",
      "4     120,329 MAD  \n",
      "5     235,272 MAD  \n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# #### Make Predictions on new data.\n",
    "\n",
    "# %%\n",
    "# Create test configurations using exact names from dataset\n",
    "data = pd.read_csv('../dataSet/cleaned_car_data2.csv')\n",
    "\n",
    "test_configurations = [\n",
    "    ['Mercedes-Benz C Class', 'MERCEDES-BENZ', 5, 50000.0, 'Petrol', 'Automatic'],  # Luxury newer car\n",
    "    ['Toyota Corolla', 'TOYOTA', 5, 50000.0, 'Petrol', 'Manual'],     # Economy newer car\n",
    "    ['Bmw X5', 'BMW', 5, 50000.0, 'Diesel', 'Automatic'],            # Luxury SUV\n",
    "    ['Dacia Sandero', 'DACIA', 5, 50000.0, 'Petrol', 'Manual'],      # Budget car\n",
    "    ['Ford Fiesta', 'FORD', 5, 50000.0, 'Petrol', 'Manual'],         # Popular economy car\n",
    "    ['Audi A5', 'AUDI', 5, 50000.0, 'Diesel', 'Automatic']           # Premium car\n",
    "]\n",
    "\n",
    "# Use the rest of the corrected code I provided earlier with these test configurations\n",
    "# Fit the label encoders once with the training data\n",
    "le_name.fit(data['name'])\n",
    "le_manufacturer.fit(data['manufacturer'])\n",
    "le_engine.fit(data['engine'])\n",
    "le_transmission.fit(data['transmission'])\n",
    "\n",
    "results = []\n",
    "for config in test_configurations:\n",
    "    try:\n",
    "        # Create numpy array with the right shape\n",
    "        new_data = np.zeros((1, 6))\n",
    "        \n",
    "        try:\n",
    "            # Transform each feature using the appropriate encoder\n",
    "            new_data[0, 0] = le_name.transform([config[0]])[0]  # Changed from fit_transform\n",
    "            new_data[0, 1] = le_manufacturer.transform([config[1]])[0]\n",
    "            new_data[0, 2] = float(config[2])  # age\n",
    "            new_data[0, 3] = float(config[3])  # kilometerage\n",
    "            new_data[0, 4] = le_engine.transform([config[4]])[0]\n",
    "            new_data[0, 5] = le_transmission.transform([config[5]])[0]\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Unknown category in {config[0]}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "        # Normalize using the same scaler used during training\n",
    "        normalized_data = norm.transform(new_data)\n",
    "        \n",
    "        # Predict (removed the *10 multiplication)\n",
    "        price = model.predict(normalized_data)\n",
    "        \n",
    "        results.append({\n",
    "            'Car': config[0],\n",
    "            'Manufacturer': config[1],\n",
    "            'Age': config[2],\n",
    "            'Mileage': f\"{config[3]:,.0f}\",\n",
    "            'Engine': config[4],\n",
    "            'Transmission': config[5],\n",
    "            'Estimated Price': f\"{price[0]:,.0f} MAD\"  # Removed *10\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing configuration {config}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Display results\n",
    "print(\"\\nFeature Importance:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': ['name', 'manufacturer', 'age', 'kilometerage', 'engine', 'transmission'],\n",
    "    'importance': model.best_estimator_.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feature_importance)\n",
    "print(\"\\nPredictions:\")\n",
    "result_df = pd.DataFrame(results)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared Score: 0.9048598751839635\n",
      "Mean Absolute Error: 28507.76036970255\n",
      "Root Mean Squared Error: 43862.93864369047\n"
     ]
    }
   ],
   "source": [
    "# Combine training and test data\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.concatenate((y_train, y_test))\n",
    "\n",
    "# Fit the model on the combined dataset\n",
    "model.fit(X_combined, y_combined, verbose=1)\n",
    "\n",
    "# Make predictions on the combined dataset\n",
    "y_pred_combined = model.predict(X_combined)\n",
    "\n",
    "# Evaluate the model on the combined dataset\n",
    "print(\"R-squared Score:\", metrics.r2_score(y_combined, y_pred_combined))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_combined, y_pred_combined))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_combined, y_pred_combined)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "        feature  importance\n",
      "2           age    0.329431\n",
      "5  transmission    0.241670\n",
      "1  manufacturer    0.179594\n",
      "0          name    0.112557\n",
      "4        engine    0.075778\n",
      "3  kilometerage    0.060969\n",
      "\n",
      "Predictions:\n",
      "                     Car   Manufacturer  Age Mileage  Engine Transmission  \\\n",
      "0  Mercedes-Benz C Class  MERCEDES-BENZ    5  50,000  Petrol    Automatic   \n",
      "1         Toyota Corolla         TOYOTA    5  50,000  Petrol       Manual   \n",
      "2                 Bmw X5            BMW    5  50,000  Diesel    Automatic   \n",
      "3          Dacia Sandero          DACIA    5  50,000  Petrol       Manual   \n",
      "4            Ford Fiesta           FORD    5  50,000  Petrol       Manual   \n",
      "5                Audi A5           AUDI    5  50,000  Diesel    Automatic   \n",
      "\n",
      "  Estimated Price  \n",
      "0     295,195 MAD  \n",
      "1     128,416 MAD  \n",
      "2     437,590 MAD  \n",
      "3     119,119 MAD  \n",
      "4     123,987 MAD  \n",
      "5     225,432 MAD  \n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# #### Make Predictions on new data.\n",
    "\n",
    "# %%\n",
    "# Create test configurations using exact names from dataset\n",
    "data = pd.read_csv('../dataSet/cleaned_car_data2.csv')\n",
    "\n",
    "test_configurations = [\n",
    "    ['Mercedes-Benz C Class', 'MERCEDES-BENZ', 5, 50000.0, 'Petrol', 'Automatic'],  # Luxury newer car\n",
    "    ['Toyota Corolla', 'TOYOTA', 5, 50000.0, 'Petrol', 'Manual'],     # Economy newer car\n",
    "    ['Bmw X5', 'BMW', 5, 50000.0, 'Diesel', 'Automatic'],            # Luxury SUV\n",
    "    ['Dacia Sandero', 'DACIA', 5, 50000.0, 'Petrol', 'Manual'],      # Budget car\n",
    "    ['Ford Fiesta', 'FORD', 5, 50000.0, 'Petrol', 'Manual'],         # Popular economy car\n",
    "    ['Audi A5', 'AUDI', 5, 50000.0, 'Diesel', 'Automatic']           # Premium car\n",
    "]\n",
    "\n",
    "# Use the rest of the corrected code I provided earlier with these test configurations\n",
    "# Fit the label encoders once with the training data\n",
    "le_name.fit(data['name'])\n",
    "le_manufacturer.fit(data['manufacturer'])\n",
    "le_engine.fit(data['engine'])\n",
    "le_transmission.fit(data['transmission'])\n",
    "\n",
    "results = []\n",
    "for config in test_configurations:\n",
    "    try:\n",
    "        # Create numpy array with the right shape\n",
    "        new_data = np.zeros((1, 6))\n",
    "        \n",
    "        try:\n",
    "            # Transform each feature using the appropriate encoder\n",
    "            new_data[0, 0] = le_name.transform([config[0]])[0]  # Changed from fit_transform\n",
    "            new_data[0, 1] = le_manufacturer.transform([config[1]])[0]\n",
    "            new_data[0, 2] = float(config[2])  # age\n",
    "            new_data[0, 3] = float(config[3])  # kilometerage\n",
    "            new_data[0, 4] = le_engine.transform([config[4]])[0]\n",
    "            new_data[0, 5] = le_transmission.transform([config[5]])[0]\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Unknown category in {config[0]}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "        # Normalize using the same scaler used during training\n",
    "        normalized_data = norm.transform(new_data)\n",
    "        \n",
    "        # Predict (removed the *10 multiplication)\n",
    "        price = model.predict(normalized_data)\n",
    "        \n",
    "        results.append({\n",
    "            'Car': config[0],\n",
    "            'Manufacturer': config[1],\n",
    "            'Age': config[2],\n",
    "            'Mileage': f\"{config[3]:,.0f}\",\n",
    "            'Engine': config[4],\n",
    "            'Transmission': config[5],\n",
    "            'Estimated Price': f\"{price[0]:,.0f} MAD\"  # Removed *10\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing configuration {config}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Display results\n",
    "print(\"\\nFeature Importance:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': ['name', 'manufacturer', 'age', 'kilometerage', 'engine', 'transmission'],\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feature_importance)\n",
    "print(\"\\nPredictions:\")\n",
    "result_df = pd.DataFrame(results)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
